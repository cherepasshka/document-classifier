{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all necessary includes\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional functions\n",
    "\n",
    "garbage_words = stopwords.words('english') + stopwords.words('russian')\n",
    "\n",
    "\n",
    "def ClearText(text, garbage_words):\n",
    "    result = [word for word in text.lower().split() if word not in garbage_words]\n",
    "    return ' '.join(result)\n",
    "\n",
    "\n",
    "def TrainRandomForestClassifier(dataframe):\n",
    "    ngram_range = (1, 3)\n",
    "    max_features = 50000\n",
    "    n_estimators=100\n",
    "\n",
    "    vectorizer = CountVectorizer(analyzer = \"word\",\n",
    "                                tokenizer = None,\n",
    "                                preprocessor = None,\n",
    "                                stop_words = None, \n",
    "                                ngram_range = ngram_range,\n",
    "                                max_features = max_features\n",
    "                                )\n",
    "    X_train, Y_train = dataframe['X'], dataframe['target']\n",
    "    \n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    X_train = X_train.toarray()\n",
    "\n",
    "    model = RandomForestClassifier(n_estimators=n_estimators)\n",
    "    model = model.fit(X_train, Y_train)\n",
    "    return vectorizer, model\n",
    "\n",
    "\n",
    "def DepthFirstSearch(cur_folder, doc_types, file_names, doc_texts, name=''):\n",
    "    files = os.listdir()\n",
    "    cur_name = name[:]\n",
    "    if len(cur_name) != 0:\n",
    "        cur_name += '-'\n",
    "    cur_name += cur_folder\n",
    "    folders = [file for file in files if '.' not in file]\n",
    "    for folder in folders:\n",
    "        os.chdir(folder)\n",
    "        DepthFirstSearch(folder, doc_types, file_names, doc_texts, cur_name)\n",
    "        os.chdir('..')\n",
    "    if len(folders) == 0:\n",
    "        for file in files:\n",
    "            doc_types.append(cur_name)\n",
    "            file_names.append(file)\n",
    "            doc_texts.append('') # need to proceed the text layer of document \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               file_name            doc_type doc_text\n",
      "0              act-1.pdf      act-first page         \n",
      "1              act-2.pdf      act-first page         \n",
      "2              act-3.pdf      act-first page         \n",
      "3          invoice-1.pdf  invoice-first page         \n",
      "4          invoice-2.pdf  invoice-first page         \n",
      "5            other-1.pdf               other         \n",
      "6             upd1-1.pdf      upd-first page         \n",
      "7  waybill-invoice-2.pdf             waybill         \n"
     ]
    }
   ],
   "source": [
    "# read input\n",
    "\n",
    "doc_types, file_names, doc_texts = [], [], []\n",
    "\n",
    "dataset_path = 'for training'\n",
    "os.chdir(dataset_path)\n",
    "DepthFirstSearch('', doc_types, file_names, doc_texts)\n",
    "os.chdir('..')\n",
    "df = pd.DataFrame({'file_name': file_names, 'doc_type': doc_types, 'doc_text' : doc_texts})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               file_name              target X\n",
      "0              act-1.pdf      act-first page  \n",
      "1              act-2.pdf      act-first page  \n",
      "2              act-3.pdf      act-first page  \n",
      "3          invoice-1.pdf  invoice-first page  \n",
      "4          invoice-2.pdf  invoice-first page  \n",
      "5            other-1.pdf               other  \n",
      "6             upd1-1.pdf      upd-first page  \n",
      "7  waybill-invoice-2.pdf             waybill  \n"
     ]
    }
   ],
   "source": [
    "# modify input\n",
    "\n",
    "for i in range(len(df['doc_text'])):\n",
    "    df['doc_text'][i] = ClearText(df['doc_text'][i], garbage_words)\n",
    "df = df.rename(columns={'doc_type' : 'target', 'doc_text' : 'X'})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training (0.6 of dataframe) validation (0.2 of dataframe) and test (0.2 of dataframe)\n",
    "\n",
    "train, validate, test = np.split(df.sample(frac=1), [int(0.6 * len(df)), int(0.8 * len(df))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "\n",
    "model, vectorizer = TrainRandomForestClassifier(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write model to file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assess accuracy of the model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
